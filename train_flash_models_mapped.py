#!/usr/bin/env python3
"""
Train FLASH models with the 100k dataset - with correct column mapping
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix
import xgboost as xgb
import joblib
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Map generated dataset columns to FLASH 45 features
COLUMN_MAPPING = {
    # Financial (7 features)
    'monthly_recurring_revenue': 'annual_revenue_run_rate',  # Will divide by 12
    'revenue_growth_rate_percent': 'revenue_growth_rate_percent',
    'gross_margin_percent': 'gross_margin_percent',
    'burn_multiple': 'burn_multiple',
    'runway_months': 'runway_months',
    'customer_acquisition_cost': 'ltv_cac_ratio',  # Will derive CAC from LTV/CAC
    'customer_lifetime_value': 'ltv_cac_ratio',  # Will derive LTV from LTV/CAC
    
    # Team (10 features)
    'team_size_full_time': 'team_size_full_time',
    'team_size_part_time': 'team_size_full_time',  # Will estimate as 20% of full time
    'founder_experience_years': 'domain_expertise_years_avg',
    'years_experience_avg': 'years_experience_avg',
    'previous_successful_exit': 'prior_successful_exits_count',  # Will convert to boolean
    'technical_team_percentage': 'team_size_full_time',  # Will estimate
    'sales_team_percentage': 'team_size_full_time',  # Will estimate
    'advisors_count': 'advisors_count',
    'board_size': 'board_advisor_experience_score',  # Will estimate
    'employee_growth_rate': 'user_growth_rate_percent',  # Proxy
    
    # Market (11 features)
    'total_addressable_market_usd': 'tam_size_usd',
    'serviceable_addressable_market_usd': 'sam_size_usd',
    'serviceable_obtainable_market_usd': 'som_size_usd',
    'market_growth_rate_percent': 'market_growth_rate_percent',
    'market_share_percent': 'som_size_usd',  # Will calculate
    'competition_intensity': 'competition_intensity',
    'market_maturity_score': 'market_growth_rate_percent',  # Will derive
    'regulatory_complexity': 'regulatory_advantage_present',  # Will convert
    'international_expansion_potential': 'scalability_score',  # Proxy
    'market_timing_score': 'market_growth_rate_percent',  # Will derive
    'customer_concentration_percent': 'customer_concentration_percent',
    
    # Product (8 features)
    'product_market_fit_score': 'product_retention_30d',  # Will normalize
    'user_growth_rate_percent': 'user_growth_rate_percent',
    'daily_active_users': 'dau_mau_ratio',  # Will derive
    'monthly_active_users': 'customer_count',  # Proxy
    'net_promoter_score': 'product_retention_90d',  # Proxy
    'user_retention_30_day': 'product_retention_30d',
    'user_retention_90_day': 'product_retention_90d',
    'feature_adoption_rate': 'product_retention_30d',  # Proxy
    
    # Capital (9 features)
    'total_funding_raised_usd': 'total_capital_raised_usd',
    'last_round_size_usd': 'total_capital_raised_usd',  # Will estimate
    'months_since_last_round': 'runway_months',  # Will estimate
    'investor_count': 'investor_tier_primary',  # Will derive
    'investor_quality_score': 'investor_tier_primary',  # Will convert
    'valuation_usd': 'total_capital_raised_usd',  # Will estimate
    'dilution_percentage': 'total_capital_raised_usd',  # Will estimate
    'cash_reserves_usd': 'cash_on_hand_usd',
    'debt_to_equity_ratio': 'has_debt'  # Will convert
}

def load_and_prepare_data():
    """Load the 100k dataset and prepare for training"""
    
    print("ðŸ“Š Loading 100k realistic startup dataset...")
    
    # Load data
    df = pd.read_csv('generated_100k_dataset.csv')
    
    print(f"âœ… Loaded {len(df)} companies")
    print(f"   Success rate: {df['success'].mean():.1%}")
    print(f"   Industries: {df['sector'].nunique()}")
    print(f"   Stages: {df['funding_stage'].nunique()}")
    
    # Create FLASH features from mapped columns
    flash_features = {}
    
    # Financial features
    flash_features['monthly_recurring_revenue'] = df['annual_revenue_run_rate'] / 12
    flash_features['revenue_growth_rate_percent'] = df['revenue_growth_rate_percent']
    flash_features['gross_margin_percent'] = df['gross_margin_percent']
    flash_features['burn_multiple'] = df['burn_multiple']
    flash_features['runway_months'] = df['runway_months']
    # Derive CAC and LTV from ratio (assume CAC = $1000 base)
    flash_features['customer_acquisition_cost'] = 1000
    flash_features['customer_lifetime_value'] = df['ltv_cac_ratio'] * 1000
    
    # Team features
    flash_features['team_size_full_time'] = df['team_size_full_time']
    flash_features['team_size_part_time'] = df['team_size_full_time'] * 0.2  # Estimate
    flash_features['founder_experience_years'] = df['domain_expertise_years_avg']
    flash_features['years_experience_avg'] = df['years_experience_avg']
    flash_features['previous_successful_exit'] = (df['prior_successful_exits_count'] > 0).astype(int)
    flash_features['technical_team_percentage'] = 40 + np.random.normal(0, 10, len(df))  # Estimate
    flash_features['sales_team_percentage'] = 30 + np.random.normal(0, 10, len(df))  # Estimate
    flash_features['advisors_count'] = df['advisors_count']
    flash_features['board_size'] = 3 + df['board_advisor_experience_score']  # Estimate
    flash_features['employee_growth_rate'] = df['user_growth_rate_percent'] * 0.3  # Proxy
    
    # Market features
    flash_features['total_addressable_market_usd'] = df['tam_size_usd']
    flash_features['serviceable_addressable_market_usd'] = df['sam_size_usd']
    flash_features['serviceable_obtainable_market_usd'] = df['som_size_usd']
    flash_features['market_growth_rate_percent'] = df['market_growth_rate_percent']
    flash_features['market_share_percent'] = (df['som_size_usd'] / df['sam_size_usd'] * 100).fillna(0)
    flash_features['competition_intensity'] = df['competition_intensity']
    flash_features['market_maturity_score'] = 1 - (df['market_growth_rate_percent'] / 100).clip(0, 1)
    flash_features['regulatory_complexity'] = df['regulatory_advantage_present'] * 3 + 2
    flash_features['international_expansion_potential'] = df['scalability_score']
    flash_features['market_timing_score'] = (df['market_growth_rate_percent'] / 50).clip(0, 1)
    flash_features['customer_concentration_percent'] = df['customer_concentration_percent']
    
    # Product features
    flash_features['product_market_fit_score'] = df['product_retention_30d'] / 100
    flash_features['user_growth_rate_percent'] = df['user_growth_rate_percent']
    flash_features['daily_active_users'] = df['customer_count'] * df['dau_mau_ratio']
    flash_features['monthly_active_users'] = df['customer_count']
    flash_features['net_promoter_score'] = (df['product_retention_90d'] - 50) * 2  # Convert to NPS scale
    flash_features['user_retention_30_day'] = df['product_retention_30d']
    flash_features['user_retention_90_day'] = df['product_retention_90d']
    flash_features['feature_adoption_rate'] = df['product_retention_30d'] * 0.8
    
    # Capital features
    flash_features['total_funding_raised_usd'] = df['total_capital_raised_usd']
    flash_features['last_round_size_usd'] = df['total_capital_raised_usd'] * 0.4  # Estimate last round
    flash_features['months_since_last_round'] = 12 + np.random.randint(-6, 18, len(df))
    # Map investor tier to numeric
    investor_tier_map = {'Angel': 1, 'Tier3': 2, 'Tier2': 3, 'Tier1': 4}
    investor_tier_numeric = df['investor_tier_primary'].map(investor_tier_map).fillna(1)
    
    flash_features['investor_count'] = investor_tier_numeric * 5 + 3
    flash_features['investor_quality_score'] = investor_tier_numeric
    flash_features['valuation_usd'] = df['total_capital_raised_usd'] * 4  # 4x multiple estimate
    flash_features['dilution_percentage'] = 25 + np.random.normal(0, 10, len(df))
    flash_features['cash_reserves_usd'] = df['cash_on_hand_usd']
    flash_features['debt_to_equity_ratio'] = df['has_debt'] * 0.3
    
    # Create DataFrame
    X = pd.DataFrame(flash_features)
    y = df['success']
    
    # Clean up any infinities or NaNs
    X = X.replace([np.inf, -np.inf], np.nan)
    X = X.fillna(0)
    
    # Clip extreme values
    for col in X.columns:
        if X[col].dtype in ['float64', 'int64']:
            q99 = X[col].quantile(0.99)
            q01 = X[col].quantile(0.01)
            X[col] = X[col].clip(q01, q99)
    
    return X, y, df

def engineer_features(X):
    """Add engineered features based on domain knowledge"""
    
    X = X.copy()
    
    # Financial health ratios
    X['ltv_cac_ratio'] = X['customer_lifetime_value'] / (X['customer_acquisition_cost'] + 1)
    X['revenue_per_employee'] = X['monthly_recurring_revenue'] / (X['team_size_full_time'] + 1)
    X['burn_efficiency'] = X['revenue_growth_rate_percent'] / (X['burn_multiple'] + 0.1)
    
    # Market opportunity scores
    X['market_capture_potential'] = X['market_share_percent'] * X['market_growth_rate_percent'] / 100
    X['tam_per_competitor'] = X['total_addressable_market_usd'] / (X['competition_intensity'] * 10 + 1)
    
    # Team quality metrics
    X['team_experience_score'] = X['founder_experience_years'] * X['years_experience_avg'] / 100
    X['team_completeness'] = (X['technical_team_percentage'] + X['sales_team_percentage']) / 100
    
    # Product strength indicators
    X['retention_score'] = (X['user_retention_30_day'] + X['user_retention_90_day']) / 2
    X['engagement_score'] = X['daily_active_users'] / (X['monthly_active_users'] + 1)
    X['product_velocity'] = X['user_growth_rate_percent'] * X['feature_adoption_rate'] / 100
    
    # Capital efficiency
    X['funding_efficiency'] = X['monthly_recurring_revenue'] * 12 / (X['total_funding_raised_usd'] + 1)
    X['months_per_round'] = X['months_since_last_round'] / (X['investor_count'] + 1)
    
    return X

def train_models(X_train, y_train, X_val, y_val):
    """Train the FLASH models"""
    
    print("\nðŸ¤– Training FLASH Models...")
    
    # Random Forest - good for feature interactions
    print("\nðŸŒ² Training Random Forest...")
    rf_model = RandomForestClassifier(
        n_estimators=200,
        max_depth=20,
        min_samples_split=20,
        min_samples_leaf=10,
        random_state=42,
        n_jobs=-1
    )
    rf_model.fit(X_train, y_train)
    rf_pred = rf_model.predict_proba(X_val)[:, 1]
    rf_auc = roc_auc_score(y_val, rf_pred)
    print(f"   Random Forest AUC: {rf_auc:.4f}")
    
    # XGBoost - good for non-linear patterns
    print("\nðŸš€ Training XGBoost...")
    xgb_model = xgb.XGBClassifier(
        n_estimators=200,
        max_depth=10,
        learning_rate=0.05,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        use_label_encoder=False,
        eval_metric='logloss'
    )
    xgb_model.fit(X_train, y_train)
    xgb_pred = xgb_model.predict_proba(X_val)[:, 1]
    xgb_auc = roc_auc_score(y_val, xgb_pred)
    print(f"   XGBoost AUC: {xgb_auc:.4f}")
    
    # Ensemble predictions
    ensemble_pred = (rf_pred + xgb_pred) / 2
    ensemble_auc = roc_auc_score(y_val, ensemble_pred)
    print(f"\nðŸŽ¯ Ensemble AUC: {ensemble_auc:.4f}")
    
    return rf_model, xgb_model, ensemble_auc

def calculate_camp_scores(X, model):
    """Calculate CAMP scores based on feature importance"""
    
    print("\nðŸ•ï¸ Calculating CAMP Scores...")
    
    # Get feature importance
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    # Print top features
    print("\nðŸ“Š Top 10 Most Important Features:")
    for idx, row in feature_importance.head(10).iterrows():
        print(f"   {row['feature']}: {row['importance']:.4f}")
    
    # Define CAMP categories
    camp_mapping = {
        'capital': ['burn_multiple', 'runway_months', 'funding_efficiency', 
                   'cash_reserves_usd', 'total_funding_raised_usd'],
        'advantage': ['product_market_fit_score', 'net_promoter_score', 
                     'retention_score', 'user_growth_rate_percent'],
        'market': ['total_addressable_market_usd', 'market_growth_rate_percent',
                  'market_share_percent', 'competition_intensity'],
        'people': ['founder_experience_years', 'team_experience_score',
                  'previous_successful_exit', 'team_completeness']
    }
    
    # Calculate weighted scores
    camp_scores = {}
    for category, features in camp_mapping.items():
        weights = []
        for feat in features:
            if feat in feature_importance['feature'].values:
                weight = feature_importance[feature_importance['feature'] == feat]['importance'].values[0]
                weights.append(weight)
            else:
                weights.append(0)
        
        camp_scores[category] = np.mean(weights) if weights else 0
    
    # Normalize scores
    total = sum(camp_scores.values())
    if total > 0:
        camp_scores = {k: v/total for k, v in camp_scores.items()}
    
    print("\nðŸ•ï¸ CAMP Score Weights:")
    for category, score in camp_scores.items():
        print(f"   {category.title()}: {score:.1%}")
    
    return camp_scores

def save_production_models(rf_model, xgb_model, scaler, camp_scores):
    """Save models in production format"""
    
    print("\nðŸ’¾ Saving Production Models...")
    
    import os
    os.makedirs('models/production_real_data', exist_ok=True)
    
    # Save models
    joblib.dump(rf_model, 'models/production_real_data/random_forest_model.pkl')
    joblib.dump(xgb_model, 'models/production_real_data/xgboost_model.pkl')
    joblib.dump(scaler, 'models/production_real_data/feature_scaler.pkl')
    
    # Save CAMP scores
    with open('models/production_real_data/camp_scores.json', 'w') as f:
        json.dump(camp_scores, f, indent=2)
    
    # Save metadata
    metadata = {
        'training_date': datetime.now().isoformat(),
        'dataset_size': 100000,
        'success_rate': 0.191,
        'feature_count': 45,
        'engineered_features': 13,
        'models': {
            'random_forest': {
                'type': 'RandomForestClassifier',
                'n_estimators': 200,
                'max_depth': 20
            },
            'xgboost': {
                'type': 'XGBClassifier',
                'n_estimators': 200,
                'max_depth': 10
            }
        }
    }
    
    with open('models/production_real_data/metadata.json', 'w') as f:
        json.dump(metadata, f, indent=2)
    
    print("âœ… Models saved to models/production_real_data/")

def main():
    """Main training pipeline"""
    
    print("ðŸš€ FLASH Model Training with 100k Realistic Dataset")
    print("=" * 60)
    
    # Load and prepare data
    X, y, df = load_and_prepare_data()
    
    # Engineer features
    print("\nðŸ”§ Engineering Features...")
    X_engineered = engineer_features(X)
    print(f"   Total features: {X_engineered.shape[1]}")
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X_engineered, y, test_size=0.2, random_state=42, stratify=y
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
    )
    
    print(f"\nðŸ“Š Data Split:")
    print(f"   Training: {len(X_train):,} samples")
    print(f"   Validation: {len(X_val):,} samples")
    print(f"   Test: {len(X_test):,} samples")
    
    # Scale features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    X_test_scaled = scaler.transform(X_test)
    
    # Train models
    rf_model, xgb_model, val_auc = train_models(
        X_train_scaled, y_train, X_val_scaled, y_val
    )
    
    # Test set evaluation
    print("\nðŸŽ¯ Final Test Set Evaluation...")
    rf_test_pred = rf_model.predict_proba(X_test_scaled)[:, 1]
    xgb_test_pred = xgb_model.predict_proba(X_test_scaled)[:, 1]
    ensemble_test_pred = (rf_test_pred + xgb_test_pred) / 2
    
    test_auc = roc_auc_score(y_test, ensemble_test_pred)
    print(f"   Test AUC: {test_auc:.4f}")
    
    # Classification report
    y_pred = (ensemble_test_pred > 0.5).astype(int)
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred, target_names=['Failed', 'Successful']))
    
    # Calculate CAMP scores
    camp_scores = calculate_camp_scores(X_engineered, rf_model)
    
    # Save models
    save_production_models(rf_model, xgb_model, scaler, camp_scores)
    
    print("\n" + "="*60)
    print("ðŸŽ‰ Training Complete!")
    print(f"   Final Test AUC: {test_auc:.4f}")
    print("   Models saved and ready for production!")
    print("\nðŸš€ FLASH now has models trained on realistic patterns!")

if __name__ == "__main__":
    main()